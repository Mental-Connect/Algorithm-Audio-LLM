{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model: directory is the base model which is used to make the detections\n",
    "\n",
    "vad_model: If the audio clips are larger than 60 sec this model splits the audio clips into smaller clips and use for processing\n",
    "\n",
    "vad_kwargs: This is the maximum splitted clip time by vad model\n",
    "\n",
    "hub: optional: ms (default) to download models from ModelScope. Use hf to download models from Hugging Face.\n",
    "\n",
    "\n",
    "model(str): model name in the Model Repository, or a model path on local disk.\n",
    "\n",
    "device(str): cuda:0 (default gpu0) for using GPU for inference, specify cpu for using CPU.\n",
    "\n",
    "ncpu(int): 4 (default), sets the number of threads for CPU internal operations.\n",
    "\n",
    "output_dir(str): None (default), set this to specify the output path for the results.\n",
    "\n",
    "batch_size(int): 1 (default), the number of samples per batch during decoding.\n",
    "\n",
    "hub(str)：ms (default) to download models from ModelScope. Use hf to download models from Hugging Face.\n",
    "\n",
    "**kwargs(dict): Any parameters found in config.yaml can be directly specified here, for instance, the maximum segmentation length in the vad model max_single_segment_time=6000 (milliseconds).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MP3 file\n",
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\LLM_work\\SenseVoiceSmall\\example\\zh.mp3'\n",
    "audio_array, sample_rate = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 48000\n",
      "Audio Array: [ 0.0000000e+00 -1.0005779e-14 -7.1443096e-15 ...  2.2035025e-10\n",
      "  2.1887764e-10  2.0613053e-10]\n",
      "Audio Array datatype is Array:  True\n"
     ]
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Sample Rate:\", sample_rate)\n",
    "print(\"Audio Array:\", audio_array)\n",
    "print(\"Audio Array datatype is Array: \", isinstance(audio_array,np.ndarray) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the Audio so it matches to the requirement of the model\n",
    "audio_16KHz = librosa.resample(audio_array,\n",
    "                               orig_sr=sample_rate,\n",
    "                               target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"FunAudioLLM/SenseVoiceSmall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenseVoiceSmall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 11:41:14,726 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "rtf_avg: 0.042: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开饭时间早上9点至下午5点。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_dir = r'C:/Users/Administrator/Desktop/LLM_work/SenseVoiceSmall'\n",
    "# pretrained_model_path=  r'C:\\Users\\Administrator\\Desktop\\LLM_work\\SenseVoiceSmall\\model.pt'\n",
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "    # init_param = pretrained_model_path\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paraformer-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.035: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开放时间早上九点至下午五点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='paraformer-zh',  # This is the directory of model path\n",
    "    device=\"cuda:0\",  # \"cuda:0\" for GPU (if CUDA is available) or \"cpu\" for CPU.\n",
    "    hub=\"hf\",   # \"hf\" for Hugging Face Hub, \"local\" for local filesystem.\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"zn\",\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ct-punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 12:02:22,218 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "c:\\Users\\Administrator\\Desktop\\LLM_work\\SenseVoiceSmall\\sensevoice_env\\Lib\\site-packages\\funasr\\train_utils\\load_pretrained_model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n",
      "rtf_avg: -0.022: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'text': '那今天的会就到这里吧，happy new year,明年见。', 'punc_array': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3])}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This model is used to detect the punctuation in the generated text\n",
    "model = AutoModel(model=\"ct-punc\", model_revision=\"v2.0.4\")\n",
    "res = model.generate(input=\"那今天的会就到这里吧 happy new year 明年见\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fsmn-vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 12:02:39,634 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 27.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'value': [[420, 5600]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "model = AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\")\n",
    "\n",
    "res = model.generate(input=audio_16KHz)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 12:04:56,642 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2024-09-06 12:05:00,066 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "rtf_avg: 0.047: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开饭时间早上9点至下午5点。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "    # vad_model=\"fsmn-vad\",\n",
    "    # vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    "    punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensevoice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
