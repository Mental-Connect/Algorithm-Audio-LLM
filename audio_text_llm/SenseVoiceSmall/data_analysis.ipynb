{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the libraries\n",
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MP3 file\n",
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\LLM_work\\SenseVoiceSmall\\example\\zh.mp3'\n",
    "audio_array, sample_rate = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 48000\n",
      "Audio Array: [ 0.0000000e+00 -1.0005779e-14 -7.1443096e-15 ...  2.2035025e-10\n",
      "  2.1887764e-10  2.0613053e-10]\n",
      "Audio Array datatype is Array:  True\n"
     ]
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Sample Rate:\", sample_rate)\n",
    "print(\"Audio Array:\", audio_array)\n",
    "print(\"Audio Array datatype is Array: \", isinstance(audio_array,np.ndarray) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the Audio so it matches to the requirement of the model\n",
    "audio_16KHz = librosa.resample(audio_array,\n",
    "                               orig_sr=sample_rate,\n",
    "                               target_sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"FunAudioLLM/SenseVoiceSmall\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenseVoiceSmall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:10:13,153 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "c:\\Users\\Administrator\\Desktop\\Backend-LLM\\audio_text_llm\\SenseVoiceSmall\\sensevoice_env\\Lib\\site-packages\\funasr\\train_utils\\load_pretrained_model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  src_state = torch.load(path, map_location=map_location)\n",
      "rtf_avg: 0.044: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.01it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开饭时间早上9点至下午5点。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_dir = r'C:/Users/Administrator/Desktop/LLM_work/SenseVoiceSmall'\n",
    "# pretrained_model_path=  r'C:\\Users\\Administrator\\Desktop\\LLM_work\\SenseVoiceSmall\\model.pt'\n",
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "    # init_param = pretrained_model_path\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paraformer-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 9993.58it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/1 [00:00<?, ?it/s]c:\\Users\\Administrator\\Desktop\\Backend-LLM\\audio_text_llm\\SenseVoiceSmall\\sensevoice_env\\Lib\\site-packages\\funasr\\models\\paraformer\\model.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n",
      "c:\\Users\\Administrator\\Desktop\\Backend-LLM\\audio_text_llm\\SenseVoiceSmall\\sensevoice_env\\Lib\\site-packages\\funasr\\models\\paraformer\\cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n",
      "rtf_avg: 0.042: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.16it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开放时间早上九点至下午五点\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='paraformer-zh',  # This is the directory of model path\n",
    "    device=\"cuda:0\",  # \"cuda:0\" for GPU (if CUDA is available) or \"cpu\" for CPU.\n",
    "    hub=\"hf\",   # \"hf\" for Hugging Face Hub, \"local\" for local filesystem.\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"zn\",\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ct-punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:10:22,487 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "Downloading [README.md]: 100%|██████████| 10.6k/10.6k [00:02<00:00, 5.29kB/s]\n",
      "Building prefix dict from the default dictionary ...\n",
      "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "DEBUG:jieba:Loading model from cache C:\\Users\\Administrator\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.393 seconds.\n",
      "DEBUG:jieba:Loading model cost 0.393 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n",
      "rtf_avg: -0.026: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 37.55it/s]                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'text': '那今天的会就到这里吧，happy new year,明年见。', 'punc_array': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3])}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This model is used to detect the punctuation in the generated text\n",
    "model = AutoModel(model=\"ct-punc\", model_revision=\"v2.0.4\")\n",
    "res = model.generate(input=\"那今天的会就到这里吧 happy new year 明年见\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fsmn-vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:10:44,028 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "rtf_avg: 0.005: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 31.15it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'rand_key_2yW4Acq9GFz6Y', 'value': [[420, 5600]]}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "\n",
    "model = AutoModel(model=\"fsmn-vad\", model_revision=\"v2.0.4\")\n",
    "\n",
    "res = model.generate(input=audio_16KHz)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.1.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 14:10:47,807 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2024-09-06 14:10:51,760 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "Downloading [README.md]: 100%|██████████| 10.6k/10.6k [00:01<00:00, 6.34kB/s]\n",
      "rtf_avg: 0.048: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.67it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开饭时间早上9点至下午5点。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "    # vad_model=\"fsmn-vad\",\n",
    "    # vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    "    punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensevoice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
