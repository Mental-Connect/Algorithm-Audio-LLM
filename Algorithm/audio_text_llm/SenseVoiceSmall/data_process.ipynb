{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "# Parameters for recording\n",
    "duration = 5  # seconds\n",
    "sample_rate = 22050  # Hz, the default for librosa or your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16808\\550681422.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, sample_rate = librosa.load(audio_path, sr = None)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\Backend-Algorithm-LLM\\Algorithm\\audio_text_llm\\SenseVoiceSmall\\audio_sample\\听故事学中文 Learn Chinese with 12 Stories - The Easiest Way to Improve Chinese.mp3'\n",
    "speech, sample_rate = librosa.load(audio_path, sr = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the sample rate is not 16,000 Hz, resample the audio\n",
    "target_sample_rate = 16000\n",
    "if sample_rate != target_sample_rate:\n",
    "    speech = librosa.resample(speech, orig_sr=sample_rate, target_sr=target_sample_rate)\n",
    "    sample_rate = target_sample_rate  # Update the sample rate\n",
    "\n",
    "speech = speech[:int(900000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Function to create a band-pass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Function to apply the band-pass filter\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# Set your low and high cut-off frequencies (in Hz)\n",
    "lowcut = 1000.0\n",
    "highcut = 3400.0\n",
    "\n",
    "# Apply the band-pass filter\n",
    "filtered_speech = bandpass_filter(speech, lowcut, highcut, target_sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate: 16000\n",
      "Audio Array: [8.80059615e-13 5.30707346e-12 1.38455081e-11 ... 6.20456824e-05\n",
      " 3.45207431e-05 1.03955002e-05]\n",
      "Audio Array datatype is Array:  True\n"
     ]
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Sample Rate:\", sample_rate)\n",
    "print(\"Audio Array:\", filtered_speech)\n",
    "print(\"Audio Array datatype is Array: \", isinstance(speech,np.ndarray) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New version available: 1.1.9. Your current version is 1.1.2.\n",
      "Please use the command \"pip install -U funasr\" to upgrade.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-08 14:20:43,582 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    }
   ],
   "source": [
    "chunk_size = [0, 10, 5]  # [0, 10, 5] 600ms, [0, 8, 4] 480ms\n",
    "encoder_chunk_look_back = 4  # number of chunks to lookback for encoder self-attention\n",
    "decoder_chunk_look_back = 1  # number of encoder chunks to lookback for decoder cross-attention\n",
    "\n",
    "model = AutoModel(model=\"paraformer-zh-streaming\", model_revision=\"v2.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.144: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.49it/s]                                                                                          \n",
      "rtf_avg: 0.119: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.79it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.34it/s]                                                                                          \n",
      "rtf_avg: 0.126: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.14it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.90it/s]                                                                                          \n",
      "rtf_avg: 0.122: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.54it/s]                                                                                          \n",
      "rtf_avg: 0.115: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.37it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.98it/s]                                                                                          \n",
      "rtf_avg: 0.120: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.62it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.04it/s]                                                                                          \n",
      "rtf_avg: 0.117: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.02it/s]                                                                                          \n",
      "rtf_avg: 0.182: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.10it/s]                                                                                          \n",
      "rtf_avg: 0.167: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.92it/s]                                                                                          \n",
      "rtf_avg: 0.152: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.82it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.02it/s]                                                                                          \n",
      "rtf_avg: 0.120: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.85it/s]                                                                                          \n",
      "rtf_avg: 0.148: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.07it/s]                                                                                          \n",
      "rtf_avg: 0.151: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.88it/s]                                                                                          \n",
      "rtf_avg: 0.187: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.80it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.84it/s]                                                                                          \n",
      "rtf_avg: 0.115: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.34it/s]                                                                                          \n",
      "rtf_avg: 0.173: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.46it/s]                                                                                          \n",
      "rtf_avg: 0.169: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.72it/s]                                                                                          \n",
      "rtf_avg: 0.186: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.78it/s]                                                                                          \n",
      "rtf_avg: 0.211: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.83it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.37it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.40it/s]                                                                                          \n",
      "rtf_avg: 0.154: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.71it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.17it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.84it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.39it/s]                                                                                          \n",
      "rtf_avg: 0.152: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.96it/s]                                                                                          \n",
      "rtf_avg: 0.118: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.85it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.84it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.50it/s]                                                                                          \n",
      "rtf_avg: 0.165: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.02it/s]                                                                                          \n",
      "rtf_avg: 0.124: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.32it/s]                                                                                          \n",
      "rtf_avg: 0.169: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.77it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.85it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.55it/s]                                                                                          \n",
      "rtf_avg: 0.147: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.21it/s]                                                                                          \n",
      "rtf_avg: 0.164: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.171: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.58it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.40it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.89it/s]                                                                                          \n",
      "rtf_avg: 0.198: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.25it/s]                                                                                          \n",
      "rtf_avg: 0.137: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.00it/s]                                                                                          \n",
      "rtf_avg: 0.190: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.72it/s]                                                                                          \n",
      "rtf_avg: 0.149: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.03it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.08it/s]                                                                                          \n",
      "rtf_avg: 0.161: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.25it/s]                                                                                          \n",
      "rtf_avg: 0.161: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.32it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.70it/s]                                                                                          \n",
      "rtf_avg: 0.125: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.06it/s]                                                                                          \n",
      "rtf_avg: 0.176: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.38it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.32it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.61it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.51it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.67it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.36it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.63it/s]                                                                                          \n",
      "rtf_avg: 0.153: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.71it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.50it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.61it/s]                                                                                          \n",
      "rtf_avg: 0.210: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.77it/s]                                                                                          \n",
      "rtf_avg: 0.182: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.02it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.98it/s]                                                                                          \n",
      "rtf_avg: 0.151: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.87it/s]                                                                                          \n",
      "rtf_avg: 0.121: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.63it/s]                                                                                          \n",
      "rtf_avg: 0.160: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.41it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.35it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.44it/s]                                                                                          \n",
      "rtf_avg: 0.121: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.74it/s]                                                                                          \n",
      "rtf_avg: 0.157: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.56it/s]                                                                                          \n",
      "rtf_avg: 0.156: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.66it/s]                                                                                          \n",
      "rtf_avg: 0.126: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 12.95it/s]                                                                                          \n",
      "rtf_avg: 0.166: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.89it/s]                                                                                          \n",
      "rtf_avg: 0.194: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.43it/s]                                                                                          \n",
      "rtf_avg: 0.145: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 11.32it/s]                                                                                          \n",
      "rtf_avg: 0.167: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.91it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.31it/s]                                                                                          \n",
      "rtf_avg: 0.158: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.45it/s]                                                                                          \n",
      "rtf_avg: 0.162: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.14it/s]                                                                                          \n",
      "rtf_avg: 0.155: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.57it/s]                                                                                          \n",
      "rtf_avg: 0.124: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.24it/s]                                                                                          \n",
      "rtf_avg: 0.154: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.68it/s]                                                                                          \n",
      "rtf_avg: 0.159: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 10.39it/s]                                                                                          \n",
      "rtf_avg: 0.183: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.90it/s]                                                                                          \n",
      "rtf_avg: 0.191: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  8.69it/s]                                                                                          \n",
      "rtf_avg: 0.170: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.58it/s]                                                                                          \n",
      "rtf_avg: 0.211: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  9.73it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张晓静二十九岁她来上海五年了这天早晨他向往常一样站在卫生间的洗手池前一边快速的刷着牙一边浏览着手机上客户刚刚发来的消息他的脑子里飞快地计划着今天的工作你恐怕不会相信他是那种接到工作从不抱怨而且计划和学习能力极强从不怕吃苦的人毫不夸张的说任何老板遇到他都会对他的工作能力非常满意他就职职于海的一家设计公司司\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunk_stride = chunk_size[1] * 960  # 600ms\n",
    "transcribed_text = []\n",
    "\n",
    "cache = {}\n",
    "total_chunk_num = int(len((filtered_speech) - 1) / chunk_stride + 1)\n",
    "for i in range(total_chunk_num):\n",
    "    speech_chunk = filtered_speech[i * chunk_stride:(i + 1) * chunk_stride]\n",
    "    is_final = i == total_chunk_num - 1\n",
    "    res = model.generate(input=speech_chunk, cache=cache, is_final=is_final, chunk_size=chunk_size,\n",
    "                         encoder_chunk_look_back=encoder_chunk_look_back,\n",
    "                         decoder_chunk_look_back=decoder_chunk_look_back)\n",
    "    for entry in res:\n",
    "        transcribed_text.append(entry['text'])\n",
    "final_transcript = ''.join(transcribed_text)\n",
    "print(final_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Splitting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = r'C:\\Users\\Administrator\\Desktop\\Backend-LLM\\audio_text_llm\\SenseVoiceSmall\\audio_sample\\听故事学中文 Learn Chinese with 12 Stories - The Easiest Way to Improve Chinese.mp3'\n",
    "audio_array, sampling_rate = librosa.load(audio_path, sr = None)\n",
    "# List to hold transcriptions\n",
    "transcriptions = []\n",
    "model = AutoModel(\n",
    "    model='paraformer-zh',\n",
    "    # init_param = pretrained_model_path\n",
    "    )\n",
    "for start in range(0, total_samples, chunk_samples):\n",
    "    end = min(start + chunk_samples, total_samples)\n",
    "    chunk = audio_array[start:end]\n",
    "\n",
    "    # Convert chunk to 16kHz if necessary\n",
    "    # Note: Ensure your model accepts the sample rate of 16kHz or resample if needed\n",
    "    chunk_resampled = librosa.resample(chunk, orig_sr = sampling_rate, target_sr = 16000)\n",
    "\n",
    "    # Process the chunk\n",
    "    res = model.generate(\n",
    "        input=chunk_resampled,\n",
    "        cache={},\n",
    "        language=\"auto\",\n",
    "        use_itn=True,\n",
    "        batch_size_s=60,\n",
    "        merge_vad=True,\n",
    "        merge_length_s=15,\n",
    "    )\n",
    "\n",
    "    # Get the transcribed text\n",
    "    text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "    transcriptions.append(text)\n",
    "    # Combine all transcriptions into one\n",
    "full_transcription = \" \".join(transcriptions)\n",
    "# Save the transcription to a text file\n",
    "with open(\"transcription_'paraformer-zh.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(full_transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling the Audio so it matches to the requirement of the model\n",
    "audio_16KHz = librosa.resample(audio_array,\n",
    "                               orig_sr=sampling_rate,\n",
    "                \n",
    "                               target_sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# paraformer-zh model with vad_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel(\n",
    "    model='paraformer-zh',\n",
    "     vad_model=\"fsmn-vad\",\n",
    "     vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    "    #punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_array,\n",
    "    cache={},\n",
    "    language=\"zn\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)\n",
    "# # Save the transcription to a text file\n",
    "# with open(\"./outdir/transcription_paraformer-zh.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "#     file.write(full_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SenseVoiceSmall Model with vad model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel(\n",
    "    model='iic/SenseVoiceSmall',\n",
    "     vad_model=\"fsmn-vad\",\n",
    "     vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    "    #punc_model = \"ct-punc\"\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=audio_16KHz,\n",
    "    cache={},\n",
    "    language=\"zn\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# Load the processor and model\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "# Set the sampling rate\n",
    "sample_rate = 16000\n",
    "\n",
    "def record_audio(duration=5):\n",
    "    # Record audio for a specified duration\n",
    "    audio = librosa.record(duration=duration, sr=sample_rate)\n",
    "    return audio\n",
    "\n",
    "# Example usage\n",
    "audio_data = record_audio(duration=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    audio_data = record_audio(duration=5)  # Record for 5 seconds\n",
    "\n",
    "    # Convert audio data to the format required by the model\n",
    "    audio_input = processor(audio_data, sampling_rate=sample_rate, return_tensors=\"pt\")\n",
    "\n",
    "    # Use the model to transcribe the audio\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(**audio_input)\n",
    "\n",
    "    # Decode the generated ids to get the transcription\n",
    "    transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    print(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sensevoice_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
